# -*- coding: utf-8 -*-
"""Tournament NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wcoAwqYQc8fXKVJ6-i4JE6s_OgDzsIKh
"""

import tensorflow as tf
import torch
import random
import matplotlib.pyplot as plt

class Game():
    def __init__(self,payoff_list):
        [self.R,self.S,self.T,self.P]=payoff_list
        #T>R>P>S
        if self.T <= self.R or self.R <=self.P or self.P <=self.S :
            print("Error: Game not porper IPD/DH")

    def payoff(self,s1,s2):
        if s1 =='C':
            if s2 =='C':
                return (self.R,self.R)
            elif s2 =='NC':
                return (self.S,self.T)
            else :
                print("Error: Wrong strategy input   :",s1,"   ",s2)
                return None
        elif s1 =='NC':
            if s2 =='C':
                return (self.T,self.S)
            elif s2 =='NC':
                return (self.P,self.P)
            else :
                print("Error: Wrong strategy input")
                return None
        else:
            print("Error: Wrong strategy input   :",s1,"   ",s2)
            return None

class Player():
    def __init__(self,total_turns):
    	self.starting_move='C'
    	self.my_move_history=[]
    	self.opp_move_history=[]
    	self.turn=1
    	self.total_turns=total_turns
    	self.amount=0

    def make_move(self):
    	return None

    def update_reward(self,r):
    	self.amount+=r

    def update_turn(self):
    	self.turn+=1

    def update_move_history(self, my_move, opp_move):
    	self.my_move_history.append(my_move)
    	self.opp_move_history.append(opp_move)

    def total_reward(self):
    	return self.amount

    def new_match(self):
    	self.starting_move='C'
    	self.my_move_history=[]
    	self.opp_move_history=[]
    	self.turn=1
    	self.amount=0

    def change_move(self,move):
    	if move=='C':
    		return 'NC'
    	elif move =='NC':
    		return 'C'
    	else:
    		print("Error: not a valid choice")
    		return None

class ALLC(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='C'
		self.type="ALLC"

	def make_move(self):
		return 'C'

class ALLD(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='NC'
		self.type="ALLD"

	def make_move(self):
		return 'NC'

class TFT(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='C'
		self.type="TFT"

	def make_move(self):
		if self.turn==1:
			return self.starting_move
		else:
			return self.opp_move_history[-1]

class GRIM(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='C'
		self.opp_defected=False
		self.type="GRIM"

	def make_move(self):
		if self.turn==1:
			return self.starting_move
		else:
			if self.opp_move_history[-1]=='NC':
				self.opp_defected=True
			if self.opp_defected:
				return 'NC'
			else:
				return 'C'

class Random(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		if random.random()<0.5:
			self.starting_move= 'NC'
		self.type="Random"

	def make_move(self):
		if random.random()<0.5:
			return 'C'
		else:
			return 'NC'

class STFT(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='NC'
		self.type="STFT"

	def make_move(self):
		if self.turn==1:
			return self.starting_move
		else:
			return self.opp_move_history[-1]

class TTFT(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='C'
		self.type="TTFT"

	def make_move(self):
		if self.turn==1:
			return self.starting_move
		elif self.turn==2:
			return self.opp_move_history[-1]
		else:
			if self.opp_move_history[-1] =='NC' or self.opp_move_history[-2]=='NC':
				return 'NC'
			return self.opp_move_history[-1]

class TFTT(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='C'
		self.type="TFTT"

	def make_move(self):
		if self.turn<=2:
			return self.starting_move
		else:
			if self.opp_move_history[-1] =='NC' and self.opp_move_history[-2]=='NC':
				return 'NC'
			return self.starting_move

class PAVLOV(Player):
	def __init__(self,total_turns):
		Player.__init__(self,total_turns)
		self.starting_move='C'
		self.type="PAVLOV"
		# if R or T repeat else change

	def make_move(self):
		if self.turn==1:
			return self.starting_move
		else:
			if self.opp_move_history[-1] =='C':
				return 'C'
			else:
				return self.change_move(self.my_move_history[-1])

class Std_Tournament():
	def __init__(self,game_para,total_turns,ptypes,pop_indx):
		self.game = Game(game_para)
		self.pop =[]
		self.total_reward=[]
		self.total_turns=total_turns
		self.ptypes=ptypes
		self.pop_indx=pop_indx
		self.generate_fresh_pop()
		

	def generate_fresh_pop(self):
		self.pop=[]
		for pi in self.pop_indx:
			self.pop.append(self.ptypes[pi](self.total_turns))

	def play_match(self,p1_indx,p2_indx):
		self.generate_fresh_pop()
		p1=self.pop[p1_indx]
		p2=self.pop[p2_indx]

		for i in range(0,self.total_turns):
			p1_move=p1.make_move()
			p2_move=p2.make_move()
			p1_reward,p2_reward = self.game.payoff(p1_move,p2_move)

			p1.update_turn()
			p1.update_reward(p1_reward)
			p1.update_move_history(p1_move,p2_move)

			p2.update_turn()
			p2.update_reward(p2_reward)
			p2.update_move_history(p2_move,p1_move)

		self.total_reward[p1_indx]+=p1.total_reward()
		self.total_reward[p2_indx]+=p2.total_reward()

	def play_RR(self):
		self.total_reward=[]
		for pi in self.pop_indx:
			self.total_reward.append(0)

		for p1_indx in range(0,len(self.pop)-1):
			for p2_indx in range(p1_indx+1,len(self.pop)):
				self.play_match(p1_indx,p2_indx)

		return self.total_reward

	def pop_type(self):
		return list(map(type,self.pop))

def best_in_group(s):
	p_types = [ALLC,ALLD,Random,GRIM,TFT,TTFT,TFTT,STFT,PAVLOV]
	pop_indx =s
	game_para=[0.5, 0, 1, 0.2]
	total_turns=100

	T = Std_Tournament(game_para,total_turns,p_types,pop_indx)
	reward_list=T.play_RR()

	max_val=0
	for i in reward_list:
		if max_val<i:
			max_val=i

	#for indx in s:
	#	print(p_types[indx](total_turns).type,end=" ")
	result=[]#print("->",end=" ")
  
	for indx in range(len(s)):
		if reward_list[indx]==max_val:
			result.append(indx)#print(p_types[s[indx]](total_turns).type,end=" ")

	return result#print("")
	#print("")

def powerset(seq):
    """
    Returns all the subsets of this set. This is a generator.
    """
    if len(seq) <= 1:
        yield seq
        yield []
    else:
        for item in powerset(seq[1:]):
            yield [seq[0]]+item
            yield item

def to_list(s):
	l=[]
	for i in range(9):
	  l.append(0)

	for i in s:
		l[i]=1

	return l

def main():
	ix=[]
	iy=[]
	l = [1, 2, 3, 4,5,6,7,8,0]
	l = [ix for ix in powerset(l)]

	for s in l:
		if len(s)<1:
			continue
		iy.append(to_list(best_in_group(s)))
		ix.append(to_list(s))
		#
		#
		#
		#
	#
	#for i in range(len(ix)):
	#  print(ix[i],"   ->    ",iy[i])#
	#
	#
	#x=torch.FloatTensor(ix)
	#y=torch.FloatTensor(iy)
	#
	#
	#
	return ix,iy

	#

class TwoLayerNet(torch.nn.Module):
    def __init__(self, D_in, H1, H2, D_out):
        """
        In the constructor we instantiate two nn.Linear modules and assign them as
        member variables.
        """
        super(TwoLayerNet, self).__init__()
        self.linear1 = torch.nn.Linear(D_in, H1)
        self.linear2 = torch.nn.Linear(H1, H2)
        self.linear4 = torch.nn.Linear(H2, D_out)

    def forward(self, x):
        """
        In the forward function we accept a Tensor of input data and we must return
        a Tensor of output data. We can use Modules defined in the constructor as
        well as arbitrary operators on Tensors.
        """
        h_relu = self.linear1(x).clamp(min=0)
        h_relu2 = self.linear2(h_relu)
        y_pred = self.linear4(h_relu2)
        return y_pred

class ThreeLayerNet(torch.nn.Module):
    def __init__(self, D_in, H1, H2,H3, D_out):
        """
        In the constructor we instantiate two nn.Linear modules and assign them as
        member variables.
        """
        super(ThreeLayerNet, self).__init__()
        self.linear1 = torch.nn.Linear(D_in, H1)
        self.linear2 = torch.nn.Linear(H1, H2)
        self.linear3 = torch.nn.Linear(H2, H3)
        self.linear4 = torch.nn.Linear(H3, D_out)

    def forward(self, x):
        """
        In the forward function we accept a Tensor of input data and we must return
        a Tensor of output data. We can use Modules defined in the constructor as
        well as arbitrary operators on Tensors.
        """
        h_relu = self.linear1(x).clamp(min=0)
        h_relu2 = self.linear2(h_relu)
        h_relu3 = self.linear3(h_relu2)
        y_pred = self.linear4(h_relu3)
        return y_pred

def train(epoch,x,y):
  # N is batch size; D_in is input dimension;
  # H is hidden dimension; D_out is output dimension.
  N, D_in, D_out = len(x), 9, 9
  H1, H2, H3 = 20, 10,10

  # Create random Tensors to hold inputs and outputs
  #x,y =main()

  # Construct our model by instantiating the class defined above
  model = TwoLayerNet(D_in, H1, H2, D_out)
  #model = ThreeLayerNet(D_in, H1, H2, H3, D_out)

  # Construct our loss function and an Optimizer. The call to model.parameters()
  # in the SGD constructor will contain the learnable parameters of the two
  # nn.Linear modules which are members of the model.
  criterion = torch.nn.MSELoss(reduction='sum')
  optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)
  for t in range(epoch):
      # Forward pass: Compute predicted y by passing x to the model
      y_pred = model(x)

      # Compute and print loss
      loss = criterion(y_pred, y)
      #if t % 2000 == 1999 or t==1:
      #    print(t, loss.item())

      # Zero gradients, perform a backward pass, and update the weights.
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
  
  return model

def max_indx(l):
  maxindx=0
  maxval=l[maxindx]

  for i in range(len(l)):
    if maxval<l[i]:
      maxval=l[i]
      maxindx=i

  return maxindx
  
def accuracy(x,y,model):
  m=model(x)

  total=0
  passed=0
  for i in range(len(x)):
    total+=1
    mi=max_indx(m[i])
    if(y[i][mi]==1):
      passed+=1

  return passed*100/total

def random_acc(x,y):
  total=0
  passed=0
  for i in range(len(x)):
    pred_indx=random.randint(0,len(x[i])-1)
    while(x[i][pred_indx]==0):
      pred_indx=random.randint(0,len(x[[i]])-1)
    total+=1
    if pred_indx==max_indx(y[i]):
      passed+=1

    return passed*100/total

xtot,ytot =main()

def split_data():
  xtest,ytest,xtrain,ytrain=[],[],[],[]
  for i in range(len(xtot)):
    if random.random()<0.5:
      xtest.append(xtot[i])
      ytest.append(ytot[i])

    else:
      xtrain.append(xtot[i])
      ytrain.append(ytot[i])

  x=torch.FloatTensor(xtrain)
  y=torch.FloatTensor(ytrain)
  xt=torch.FloatTensor(xtest)
  yt=torch.FloatTensor(ytest)

  return x,y,xt,yt

def model_average(epoch,n):
  
  train_acc=0
  test_acc=0
  rand_acc=0

  for i in range(n):
    x,y,xt,yt =split_data()
    model=train(epoch,x,y)
    train_acc+=accuracy(x,y,model)
    test_acc+=accuracy(xt,yt,model)
    rand_acc+=random_acc(xt,yt)

  return train_acc/n,test_acc/n,rand_acc/n

def plot(n,ep_range):
  epoch_axis=[]
  test_acc=[]
  train_acc=[]
  random_acc=[]
  for epoch in ep_range:#[0,1,5,10,20,30,40,50,75,100]:#,200,400,500,750,1000,1500,2000]:
    print(epoch)
    epoch_axis.append(epoch)
    traina,testa,randa=model_average(epoch,n)
    test_acc.append(testa)
    train_acc.append(traina)
    random_acc.append(randa)
  
  plt.plot(epoch_axis,test_acc)
  plt.plot(epoch_axis,train_acc)
  plt.plot(epoch_axis,random_acc)
  plt.title('Average accuracy vs Epochs plot')
  plt.legend(['Test Accuracy','Train Accuracy','Random Accuracy'],loc='upper left', shadow=True)
  plt.show()

plot(10,[0,1,5,10,20,30,40,50,75,100])
plot(10,[100,200,400,500,750,1000,1500,2000])
#plot(10,[1000,2000,4000,5000,6000,8000,10000])

plot(1,[1000,2000,4000])#,5000,6000,8000,10000])

plot(10,[8000,10000])